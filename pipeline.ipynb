{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, ToPILImage"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set paths for pipeline\n",
    "\n",
    "I'm unsure how you're planning to reproduce the results (on Kaggle or elsewhere) so I set it up so the paths can be manually set here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4e923fa1e8bffdf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Models\n",
    "models_dir = Path('models')\n",
    "model_file = 'net_epochs-25.pytorch'    # My best model\n",
    "\n",
    "# Train data\n",
    "train_data_path = Path('data/train_imgs')\n",
    "labels_path = Path('data/labels.csv')\n",
    "\n",
    "# Test data\n",
    "test_path = Path('/kaggle/input/hat-or-no-hat-spring24-cu-denver/test_set/test_set')\n",
    "sample_submission = Path('results/sample_submission.csv') # Used to get file names for test imgs\n",
    "\n",
    "save_dir = Path('results')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e844ef2d026a6bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess training dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e90e2bbbab9dae26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def random_flip_and_rotate(self, img):\n",
    "        if random.random() < 0.5:\n",
    "            img = np.flipud(img)\n",
    "\n",
    "        if random.random() < 0.5:\n",
    "            img = np.fliplr(img)\n",
    "\n",
    "        angle = random.choice([0, 1, 2, 3])\n",
    "        img = np.rot90(img, angle)\n",
    "\n",
    "        return img.copy()\n",
    "\n",
    "\n",
    "    def preprocess_image(self, img, target_size):\n",
    "        # Resize the image\n",
    "        image = img.resize(target_size)\n",
    "        image_array = np.array(image)\n",
    "        # Normalize pixel values\n",
    "        image_array = image_array / 255.0\n",
    "        # Convert to RGB if greyscale\n",
    "        if len(image_array.shape) == 2:\n",
    "            image_array = np.stack((image_array,) * 3, axis=-1)\n",
    "        # Randomly flip and rotate image\n",
    "        image_array = self.random_flip_and_rotate(image_array)\n",
    "        return image_array.transpose(2, 0, 1)\n",
    "                         \n",
    "                         \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "                         \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_size = (64, 64)\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        image.thumbnail(target_size, Image.ANTIALIAS)\n",
    "        new_image = Image.new(\"RGB\", target_size)\n",
    "        new_image.paste(image, ((target_size[0] - image.size[0]) // 2, (target_size[1] - image.size[1]) // 2))\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(np.array(new_image))\n",
    "        image = self.preprocess_image(image, target_size)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5959422c0bfdfb5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c7ea48b4e6df56f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def init_weights(modules):\n",
    "    pass\n",
    "   \n",
    "\n",
    "class MeanShift(nn.Module):\n",
    "    def __init__(self, mean_rgb, sub):\n",
    "        super(MeanShift, self).__init__()\n",
    "\n",
    "        sign = -1 if sub else 1\n",
    "        r = mean_rgb[0] * sign\n",
    "        g = mean_rgb[1] * sign\n",
    "        b = mean_rgb[2] * sign\n",
    "\n",
    "        self.shifter = nn.Conv2d(3, 3, 1, 1, 0)\n",
    "        self.shifter.weight.data = torch.eye(3).view(3, 3, 1, 1)\n",
    "        self.shifter.bias.data   = torch.Tensor([r, g, b])\n",
    "\n",
    "        # Freeze the mean shift layer\n",
    "        for params in self.shifter.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shifter(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels, out_channels,\n",
    "                 ksize=3, stride=1, pad=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, ksize, stride, pad),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        init_weights(self.modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "        init_weights(self.modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = F.relu(out + x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EResidualBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, out_channels,\n",
    "                 group=1):\n",
    "        super(EResidualBlock, self).__init__()\n",
    "\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, groups=group),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, groups=group),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, 1, 0),\n",
    "        )\n",
    "\n",
    "        init_weights(self.modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = F.relu(out + x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_channels, scale, multi_scale, \n",
    "                 group=1):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "\n",
    "        if multi_scale:\n",
    "            self.up2 = _UpsampleBlock(n_channels, scale=2, group=group)\n",
    "            self.up3 = _UpsampleBlock(n_channels, scale=3, group=group)\n",
    "            self.up4 = _UpsampleBlock(n_channels, scale=4, group=group)\n",
    "        else:\n",
    "            self.up =  _UpsampleBlock(n_channels, scale=scale, group=group)\n",
    "\n",
    "        self.multi_scale = multi_scale\n",
    "\n",
    "    def forward(self, x, scale):\n",
    "        if self.multi_scale:\n",
    "            if scale == 2:\n",
    "                return self.up2(x)\n",
    "            elif scale == 3:\n",
    "                return self.up3(x)\n",
    "            elif scale == 4:\n",
    "                return self.up4(x)\n",
    "        else:\n",
    "            return self.up(x)\n",
    "\n",
    "\n",
    "class _UpsampleBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "\t\t\t\t n_channels, scale, \n",
    "\t\t\t\t group=1):\n",
    "        super(_UpsampleBlock, self).__init__()\n",
    "\n",
    "        modules = []\n",
    "        if scale == 2 or scale == 4 or scale == 8:\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                modules += [\n",
    "                    nn.Conv2d(n_channels, 4*n_channels, 3, 1, 1, groups=group), \n",
    "                    nn.ReLU(inplace=True)\n",
    "                ]\n",
    "                modules += [nn.PixelShuffle(2)]\n",
    "        elif scale == 3:\n",
    "            modules += [\n",
    "                nn.Conv2d(n_channels, 9*n_channels, 3, 1, 1, groups=group), \n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            modules += [nn.PixelShuffle(3)]\n",
    "\n",
    "        self.body = nn.Sequential(*modules)\n",
    "        init_weights(self.modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.b1 = ResidualBlock(64, 64)\n",
    "        self.b2 = ResidualBlock(64, 64)\n",
    "        self.b3 = ResidualBlock(64, 64)\n",
    "        self.c1 = BasicBlock(64*2, 64, 1, 1, 0)\n",
    "        self.c2 = BasicBlock(64*3, 64, 1, 1, 0)\n",
    "        self.c3 = BasicBlock(64*4, 64, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c0 = o0 = x\n",
    "\n",
    "        b1 = self.b1(o0)\n",
    "        c1 = torch.cat([c0, b1], dim=1)\n",
    "        o1 = self.c1(c1)\n",
    "        \n",
    "        b2 = self.b2(o1)\n",
    "        c2 = torch.cat([c1, b2], dim=1)\n",
    "        o2 = self.c2(c2)\n",
    "        \n",
    "        b3 = self.b3(o2)\n",
    "        c3 = torch.cat([c2, b3], dim=1)\n",
    "        o3 = self.c3(c3)\n",
    "\n",
    "        return o3\n",
    "        \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.l0 = nn.Linear(12288, 300)\n",
    "        self.l1 = nn.Linear(300, 100)\n",
    "        self.l2 = nn.Linear(100, 1)\n",
    "        \n",
    "        self.body = nn.Sequential(\n",
    "            self.flat,\n",
    "            self.l0,\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.l1,\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.l2,\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.sub_mean = MeanShift((0.4488, 0.4371, 0.4040), sub=True)\n",
    "        self.add_mean = MeanShift((0.4488, 0.4371, 0.4040), sub=False)\n",
    "        \n",
    "        self.entry = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "\n",
    "        self.b1 = Block(64, 64)\n",
    "        self.b2 = Block(64, 64)\n",
    "        self.b3 = Block(64, 64)\n",
    "        self.c1 = BasicBlock(64*2, 64, 1, 1, 0)\n",
    "        self.c2 = BasicBlock(64*3, 64, 1, 1, 0)\n",
    "        self.c3 = BasicBlock(64*4, 64, 1, 1, 0)\n",
    "        \n",
    "        self.exit = nn.Conv2d(64, 3, 3, 1, 1)\n",
    "        self.classify = Classifier([64, 3, 3])\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "        x = self.entry(x)\n",
    "        c0 = o0 = x\n",
    "\n",
    "        b1 = self.b1(o0)\n",
    "        c1 = torch.cat([c0, b1], dim=1)\n",
    "        o1 = self.c1(c1)\n",
    "        \n",
    "        b2 = self.b2(o1)\n",
    "        c2 = torch.cat([c1, b2], dim=1)\n",
    "        o2 = self.c2(c2)\n",
    "        \n",
    "        b3 = self.b3(o2)\n",
    "        c3 = torch.cat([c2, b3], dim=1)\n",
    "        o3 = self.c3(c3)\n",
    "\n",
    "        out = self.exit(o3)\n",
    "        out = self.add_mean(out)\n",
    "        \n",
    "        classification = self.classify(out)\n",
    "\n",
    "        return classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae02b42a579adf4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f61c579cba13e5de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_model = True\n",
    "epochs = 25\n",
    "\n",
    "annotations_file = labels_path\n",
    "img_dir = train_data_path\n",
    "train_data = ImageDataset(\n",
    "    annotations_file, \n",
    "    img_dir, \n",
    "    transform=ToPILImage()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=4,\n",
    "    num_workers=1,\n",
    "    shuffle=True, \n",
    ")\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0003)\n",
    "for epoch in range(1, epochs+1):\n",
    "    run_result = {'nsamples': 0, 'loss': 0}\n",
    "    \n",
    "    for p in net.parameters():\n",
    "        if p.grad is not None:\n",
    "            del p.grad  # free some memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train_bar = tqdm(train_loader)\n",
    "    for data, target in train_bar:\n",
    "        batch_size = data.size(0)\n",
    "        run_result['nsamples'] += batch_size\n",
    "\n",
    "        label = target.to(device)\n",
    "        z = data.to(device)\n",
    "        pred_prob = net(z.float())\n",
    "        \n",
    "        label = label.unsqueeze(1)\n",
    "        label = label.float()\n",
    "        net.zero_grad()\n",
    "        loss = loss_fn(pred_prob, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        run_result['loss'] += loss.item() * batch_size\n",
    "\n",
    "        train_bar.set_description(\n",
    "            desc=f\"[{epoch}/{epochs}] Loss: {run_result['loss'] / run_result['nsamples']:.4f}\")\n",
    "    \n",
    "    train_loss = run_result['loss'] / run_result['nsamples']\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "if save_model:\n",
    "    torch.save(net.state_dict(), models_dir / f'net_epochs-{epochs}.pytorch')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d327e1746d0fcfde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define test data loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17ee74c939b58c24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, file_names, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.file_names = pd.read_csv(file_names)\n",
    "        self.transform = transform\n",
    "\n",
    "    def preprocess_image(self, img, target_size):\n",
    "        # Resize the image\n",
    "        image = img.resize(target_size)\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image)\n",
    "        # Normalize pixel values\n",
    "        image_array = image_array / 255.0\n",
    "        # If the image is grayscale, convert it to RGB\n",
    "        if len(image_array.shape) == 2:\n",
    "            image_array = np.stack((image_array,) * 3, axis=-1)\n",
    "        # Randomly flip and rotate image\n",
    "        return image_array.transpose(2, 0, 1) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len([Path(file_) for file_ in Path(self.img_dir).glob(\"*\")])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_size = (64, 64)\n",
    "        img_path = os.path.join(self.img_dir, f'{self.file_names.iloc[idx, 0]}.jpg')\n",
    "        _id = self.file_names.iloc[idx, 0]\n",
    "        image = Image.open(img_path)\n",
    "        image.thumbnail(target_size, Image.ANTIALIAS)\n",
    "        new_image = Image.new(\"RGB\", target_size)\n",
    "        new_image.paste(image, ((target_size[0] - image.size[0]) // 2, (target_size[1] - image.size[1]) // 2))\n",
    "        if self.transform:\n",
    "            image = self.transform(np.array(new_image))\n",
    "        image = self.preprocess_image(image, target_size)\n",
    "        return image, _id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4af55741c9de2f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad89ed457bda5e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_data = TestDataset(\n",
    "    test_path, \n",
    "    file_names=sample_submission,\n",
    "    transform=ToPILImage()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1,\n",
    "    num_workers=1,\n",
    "    shuffle=False, \n",
    ")\n",
    "\n",
    "weights = torch.load(model_file)\n",
    "net = Net()\n",
    "net.to(device)\n",
    "net.load_state_dict(weights)\n",
    "net.eval()\n",
    "\n",
    "img_ids = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Predicting: '):\n",
    "        test_img , _id = batch\n",
    "        test_img = test_img.to(device)\n",
    "        out = net(test_img.float())\n",
    "        \n",
    "        img_ids.append(_id[0])\n",
    "        predictions.append(out.to('cpu').numpy()[0][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc3dfbcddea94bcc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Threshold and save predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dee57f50543f9790"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pos_thresh = 0.999\n",
    "\n",
    "pred_array = np.array(predictions)\n",
    "y_pred = np.where(pred_array > pos_thresh, \"Hat\", \"No Hat\")\n",
    "\n",
    "submission_dict = {'id': img_ids, 'class': y_pred}\n",
    "submission_df = pd.DataFrame.from_dict(submission_dict)\n",
    "submission_df.to_csv(save_dir / \"submission.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d006029cce94208a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
